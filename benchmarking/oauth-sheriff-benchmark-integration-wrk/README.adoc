= WRK-based JWT Integration Benchmarks
:toc: left
:toclevels: 3
:source-highlighter: highlight.js

High-performance HTTP benchmarking for JWT validation endpoints using WRK, addressing JMH limitations for REST API testing.

== Quick Start

[source,bash]
----
# Quick benchmark (30s duration, skip container lifecycle)
./mvnw clean verify -Pbenchmark,quick -pl benchmarking/benchmark-integration-wrk

# Default benchmark (50 connections, 1 minute per benchmark - GitHub CI friendly)
./mvnw clean verify -Pbenchmark -pl benchmarking/benchmark-integration-wrk

# Stress test (150 connections - moderate stress testing)
./mvnw clean verify -Pbenchmark,stress -pl benchmarking/benchmark-integration-wrk

# Maximum load test (300 connections - tests limits, expect JWT degradation)
./mvnw clean verify -Pbenchmark,max -pl benchmarking/benchmark-integration-wrk

# Start containers manually for fast iteration
cd oauth-sheriff-quarkus-parent/oauth-sheriff-quarkus-integration-tests
./scripts/start-integration-container.sh
----

== Why WRK?

* JMH benchmarks limited to 10-13k req/s due to framework overhead
* WRK achieves 20k+ req/s with lower latency
* Better connection pool management and HTTP/1.1 keep-alive
* Native C implementation with minimal overhead

== Architecture

=== WRK Execution

WRK runs via Docker for multi-architecture support (ARM64 + x86_64):

* **Docker Image**: `wrk:local` built from `Dockerfile.wrk` (Alpine-based, 10MB)
* **Lua Scripts**: Embedded in image at `/scripts/` (health_live_check.lua, jwt_benchmark.lua)
* **Wrapper**: `wrk-docker-wrapper.sh` handles one-time build and parameter pass-through
* **No Installation Required**: Docker automatically selects correct architecture variant

The wrapper is minimal (36 lines) and necessary for image build logic, TOKEN_DATA forwarding, and network configuration.

=== Components

* **WRK Scripts** (`src/main/resources/wrk-scripts/`) - Lua scripts for request generation
* **Java Post-processor** (`WrkIntegrationRunner.java`) - Parses output, fetches metrics, generates reports
* **Maven Integration** - Lifecycle management via exec-maven-plugin

=== Benchmark Flow

1. Build native Quarkus application (optional with skip flag)
2. Start Docker containers (optional with skip flag)
3. Execute WRK benchmarks
4. Process results and fetch Quarkus metrics
5. Generate JSON reports
6. Dump application logs (always)
7. Stop containers (optional with skip flag)

== Configuration

=== Maven Profiles

[cols="2,3,3", options="header"]
|===
|Profile
|Description
|Properties Set

|`benchmark`
|Enables benchmarking
|`skip.benchmark=false`

|`quick`
|Quick testing mode (30s benchmarks)
|`wrk.duration=30s`, `skip.container.lifecycle=true`

|`autoscale`
|Auto-scaled load (8 threads, 200 connections)
|`wrk.threads=8`, `wrk.connections=200`

|`stress`
|Moderate stress testing (10 threads, 150 connections)
|`wrk.threads=10`, `wrk.connections=150`

|`max`
|Maximum load testing (10 threads, 300 connections)
|`wrk.threads=10`, `wrk.connections=300`
|===

==== Load Generation Profiles

The load generation profiles are designed based on performance investigation results:

* **Default (5t/50c)**: Optimal baseline for CI and local development - excellent performance with P90 < 6ms
* **Autoscale (8t/200c)**: High load for development machines - tests moderate degradation
* **Stress (10t/150c)**: Moderate stress testing - balanced performance without severe degradation
* **Max (10t/300c)**: Maximum capacity testing - expect severe JWT validation degradation (P90 ~46ms)

==== Environment-Specific Recommendations

[cols="2,2,2,3", options="header"]
|===
|Environment
|CPU Cores
|Recommended Profile
|Expected Performance

|GitHub Actions
|2-4 vCPU
|Default (50 connections)
|Health: 37K ops/s (P90 2.5ms), JWT: 16K ops/s (P90 5.8ms)

|Local Development (typical)
|8-10 cores
|`-Pstress` (150 connections)
|Health: 50K ops/s (P90 7ms), JWT: 17K ops/s (P90 23ms)

|Local Development (high-end)
|10+ cores
|`-Pautoscale` (200 connections)
|Health: 50K ops/s (P90 9ms), JWT: 17K ops/s (P90 31ms)

|Stress Testing
|10+ cores
|`-Pmax` (300 connections)
|Health: 46K ops/s (P90 15ms), JWT: 16K ops/s (P90 46ms - degraded)
|===

Example usage:
[source,bash]
----
# Quick 30-second benchmarks (assumes containers are running)
./mvnw clean verify -Pbenchmark,quick -pl benchmarking/benchmark-integration-wrk

# Auto-scaled load for local development
./mvnw clean verify -Pbenchmark,autoscale -pl benchmarking/benchmark-integration-wrk

# Stress test with high load
./mvnw clean verify -Pbenchmark,stress -pl benchmarking/benchmark-integration-wrk

# Custom duration with specific profile
./mvnw clean verify -Pbenchmark,autoscale -Dwrk.duration=60s -pl benchmarking/benchmark-integration-wrk

# CI-friendly configuration (GitHub Actions)
./mvnw clean verify -Pbenchmark -pl benchmarking/benchmark-integration-wrk
----

=== WRK Parameters

[source,xml]
----
<wrk.duration>60s</wrk.duration>          <!-- Test duration (default: 1 minute, quick: 30s) -->
<wrk.threads>5</wrk.threads>              <!-- Number of threads (default: 5) -->
<wrk.connections>50</wrk.connections>     <!-- Concurrent connections (default: 50) -->
<wrk.timeout>2s</wrk.timeout>             <!-- Request timeout -->
<wrk.latency>true</wrk.latency>           <!-- Record latency distribution -->
----

=== Container Lifecycle Control

The `skip.container.lifecycle` property optimizes benchmark iteration:

[cols="2,3,3", options="header"]
|===
|Property Value
|Behavior
|Use Case

|`false` (default)
|Full lifecycle: build, start, stop containers
|CI/CD, first run, clean environment

|`true`
|Skip container operations, only run benchmarks
|Fast iteration, containers already running
|===

=== Service URLs

[source,xml]
----
<integration.service.url>https://localhost:10443</integration.service.url>
<keycloak.url>https://localhost:1443</keycloak.url>
<quarkus.metrics.url>https://localhost:10443</quarkus.metrics.url>
----

== Benchmarks

=== Health Check Benchmark

* **Endpoint**: `/q/health/live`
* **Script**: `health_check.lua`
* **Purpose**: Baseline performance without authentication
* **Expected**: 20,000+ req/s, <1ms latency

=== JWT Validation Benchmark

* **Endpoint**: `/api/v1/jwt/extract`
* **Script**: `jwt_benchmark.lua`
* **Purpose**: Real JWT processing performance
* **Expected**: 15,000+ req/s, 1-2ms latency

== Output

Results in `target/benchmark-results/`:

[cols="2,3", options="header"]
|===
|File
|Description

|`wrk-health-output.txt`
|Raw WRK output for health endpoint

|`wrk-health-results.json`
|Processed JSON report for health benchmark

|`wrk-jwt-output.txt`
|Raw WRK output for JWT endpoint

|`wrk-jwt-results.json`
|Processed JSON report for JWT benchmark

|`quarkus-logs.txt`
|Application logs from benchmark run
|===

=== JSON Report Format

[source,json]
----
{
  "timestamp": "2025-01-22T10:30:00Z",
  "benchmarkType": "wrk-integration",
  "serviceUrl": "https://localhost:10443",
  "performance": {
    "requests_per_second": 24184.90,
    "latency_avg_ms": 0.88,
    "total_requests": 365242,
    "duration_seconds": 15.10,
    "errors": 0
  },
  "systemMetrics": {
    // Quarkus metrics data
  }
}
----

== Performance Analysis

=== View Results

[source,bash]
----
# Check raw WRK output
cat target/benchmark-results/wrk-health-output.txt

# Analyze JSON reports
jq '.performance' target/benchmark-results/wrk-health-results.json

# Compare runs
diff <(jq '.performance' baseline/wrk-jwt-results.json) \
     <(jq '.performance' target/benchmark-results/wrk-jwt-results.json)
----

=== Performance Tuning

.Optimal Settings (Based on Performance Investigation)
[NOTE]
====
* **Threads**: 5 (balanced for typical systems)
* **Connections**: 50 (optimal performance without degradation)
* **Duration**:
  - Quick mode: 30s (fast iteration)
  - Default: 60s (balanced results)
* **Timeout**: 2s (local testing)

**Performance Profile at 50 Connections:**
* Health endpoint: P90 2.5ms, 37K ops/s
* JWT validation: P90 5.8ms, 16K ops/s, CPU 75%
====

.Performance Degradation at High Load
[WARNING]
====
JWT validation becomes CPU-bound at high connection counts:

* **100 connections**: P90 15ms, CPU 87% - degradation begins
* **150 connections**: P90 23ms, CPU 82% - moderate stress
* **200 connections**: P90 31ms, CPU 82% - severe degradation
* **300 connections**: P90 46ms, CPU 81% - critical degradation

Health checks scale better but also degrade at 300 connections (P90 15ms vs 2.5ms at 50 connections).

**Recommendation**: Use default (50 connections) for CI/CD and regular testing. Use stress/max profiles only for capacity planning.
====

== Development

=== Running Tests

[source,bash]
----
# Unit tests for WRK result parser
./mvnw test -pl benchmarking/benchmark-integration-wrk

# Integration test with containers
./mvnw verify -Pbenchmark -pl benchmarking/benchmark-integration-wrk
----

=== Adding New Benchmarks

1. Create Lua script in `src/main/resources/wrk-scripts/`
2. Add Maven execution:

[source,xml]
----
<execution>
    <id>run-wrk-custom-benchmark</id>
    <phase>integration-test</phase>
    <goals><goal>exec</goal></goals>
    <configuration>
        <skip>${skip.benchmark}</skip>
        <executable>wrk</executable>
        <arguments>
            <argument>-t${wrk.threads}</argument>
            <argument>-c${wrk.connections}</argument>
            <argument>-d${wrk.duration}</argument>
            <argument>--timeout</argument>
            <argument>${wrk.timeout}</argument>
            <argument>--latency</argument>
            <argument>-s</argument>
            <argument>${wrk.script.dir}/custom.lua</argument>
            <argument>${integration.service.url}/api/custom</argument>
        </arguments>
        <outputFile>${wrk.results.dir}/wrk-custom-output.txt</outputFile>
    </configuration>
</execution>
----

3. Add post-processing execution for results

== Troubleshooting

=== Common Issues

[cols="2,3,2", options="header"]
|===
|Issue
|Cause
|Solution

|High latency (>10ms)
|Connection pool saturation
|Reduce connections: `-Dwrk.connections=10`

|Container startup fails
|Port conflict or Docker issue
|Check ports 10443, 1443 are free

|Missing Keycloak URL error
|System property not set
|Fixed in pom.xml, update module

|Timeout errors
|Service not ready
|Increase warmup time or check logs
|===

=== Debug Mode

[source,bash]
----
# Verbose Maven output
./mvnw clean verify -Pbenchmark -X -pl benchmarking/benchmark-integration-wrk

# Monitor containers
docker compose logs -f

# Check service health
curl -k https://localhost:10443/q/health
curl -k https://localhost:1443/realms/benchmark
----

== CI/CD Integration

See link:../../.github/workflows/benchmark.yml[GitHub Actions Benchmark Workflow] for automated benchmark execution and performance regression detection.

== Related Documentation

* link:../doc/README.adoc[Main Documentation Hub]
* link:../benchmark-library/README.adoc[Library Benchmarks]
* link:../../oauth-sheriff-quarkus-parent/oauth-sheriff-quarkus-integration-tests/README.adoc[Integration Test Infrastructure]