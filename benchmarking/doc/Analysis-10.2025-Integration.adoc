= JWT Validation Performance Analysis
:toc: left
:toclevels: 2

== Executive Summary

Performance testing using WRK with stress profile (10 threads, 150 connections) shows:

* **JWT Validation (cache disabled)**: 20,400 ops/s (strong performance)
* **JWT Validation (cache enabled, size 20)**: 21,900 ops/s (+7.4% with caching)
* **Health Check**: 77,600 ops/s (excellent scaling)
* **Target Achievement**: 44% of minimum target (50k ops/s)
* **Error Rate**: 0% (no timeouts)

== WRK Stress Profile Results

=== Configuration

* **Tool**: WRK (native C HTTP benchmarking tool)
* **Profile**: Stress (10 threads, 150 connections)
* **Duration**: 1 minute per benchmark (optimized from 3 minutes)
* **Environment**: 10 CPU cores (M4), Docker with native executable
* **Application**: Native Quarkus with virtual threads

=== Performance Results

[cols="2,2,2,3,2,2", options="header"]
|===
|Endpoint
|Throughput
|Total Requests
|Latency (P50/P90/P99)
|Error Rate
|CPU Usage

|JWT Validation (cache OFF)
|20,400 ops/s
|1.22M
|6.30ms / 17.55ms / 39.38ms
|0 timeouts (0%)
|Not measured

|JWT Validation (cache ON, 20)
|21,900 ops/s
|1.31M
|5.88ms / 16.16ms / 39.98ms
|0 timeouts (0%)
|89.9% peak (74.3% avg)

|Health Check
|77,600 ops/s
|4.66M
|1.53ms / 4.79ms / 10.88ms
|0 timeouts (0%)
|56.2% peak (52.2% avg)
|===

=== Resource Utilization

* **CPU**: JWT (cache ON): 89.9% peak (74.3% avg) | Health: 56.2% peak (52.2% avg)
* **Memory**: Heap peak 127.5MB (JWT), 122.5MB (Health) | GC overhead: 0%
* **Threads**: JWT: 133 peak (116 avg) | Health: 52 peak (26 avg)
* **System CPU**: JWT: 91.1% peak | Health: 87.8% peak
* **GC**: Zero overhead (native compilation)

== Performance Analysis

=== Connection Count Investigation Results

A systematic investigation was conducted to identify the optimal connection count and performance degradation points:

[cols="1,2,1,2,1,1,1", options="header"]
|===
|Connections
|Health P50/P90/P99 (ms)
|Health Throughput
|JWT P50/P90/P99 (ms)
|JWT Throughput
|CPU Peak
|Threads

|50 (Default)
|0.573 / 1.76 / 5.32
|66.9K ops/s
|2.05 / 4.24 / 11.16
|21.6K ops/s
|100%
|63

|100
|0.92 / 3.45 / 10.09
|77.1K ops/s
|3.8 / 9.56 / 22.24
|21.6K ops/s
|80.8%
|118

|150 (Stress)
|1.75 / 5.03 / 10.8
|69.8K ops/s
|6.47 / 17.41 / 38.02
|20.1K ops/s
|80.9%
|137

|200
|2.3 / 6.75 / 17.93
|70.9K ops/s
|8.51 / 22.98 / 47.7
|20.4K ops/s
|82.0%
|174

|250
|2.82 / 8.0 / 16.2
|70.2K ops/s
|9.94 / 27.84 / 57.72
|20.6K ops/s
|79.4%
|213

|300 (Max)
|3.77 / 10.42 / 24.09
|67.9K ops/s
|12.93 / 32.51 / 61.88
|20.4K ops/s
|80.4%
|186
|===

**Key Findings:**

* **100 connections** achieves peak health throughput (77.1K ops/s) - optimal balance point
* **JWT performance** remains remarkably stable (20.1-21.6K ops/s) across all connection counts
* **50 connections** provides excellent baseline (66.9K ops/s health, 21.6K ops/s JWT) for CI/CD
* **150-250 connections** maintains consistent 70K ops/s health throughput with stable JWT performance
* **300 connections** shows slight degradation (67.9K ops/s health) but JWT remains stable at 20.4K ops/s
* **Cache effectiveness** confirmed with 100% hit rate across all runs (cache size 20)

=== Bottleneck Identification

**Root Cause: Docker Bridge Networking** ðŸŽ¯

Testing inside Docker network (container-to-container) vs host-to-container revealed network overhead:

* **Container-to-container** (50 conns, health): 0.91ms avg latency, 74.3K ops/s
* **Host-to-container** (50 conns, health): 0.573ms P50 / 1.76ms P90, 66.9K ops/s (standard test setup)
* **Improvement**: +11% throughput when bypassing Docker bridge (host network stack)
* **Conclusion**: Application is performant. Docker bridge adds overhead. Production Kubernetes pod-to-pod networking performs better.

**Secondary Bottlenecks (Application-Level):**

1. **JWT processing overhead** (55,700 ops/s gap from health check with cache enabled)
2. **Token cache effectiveness** - Cache size of 20 achieved 100% hit rate (239,156/239,156 validations), providing 7.4% throughput improvement
3. **Average validation time** - 0.33ms per cached token (measured application metric)
4. **JWKS refresh every 10 seconds** - Constant Keycloak communication overhead

=== JWT Validation Performance Breakdown

**Measured validation time:** 0.21ms average (application metric, from Prometheus)
- Total validations: 280,303 (latest benchmark run)
- Cache hit rate: 100%
- **Validation accounts for 12% of total latency** (0.21ms out of 1.72ms P50)

**Latency breakdown (50 connections baseline):**
```
JWT P50 Total:                           1.72ms (100%)
â”œâ”€ Base HTTP overhead (health baseline): 0.345ms (20%)
â”œâ”€ JWT validation (library):             0.210ms (12%)
â””â”€ Framework overhead (unexplained):     1.165ms (68%)
```

**The 68% unexplained latency likely comes from:**
- Response serialization (5-10x larger payload than health endpoint)
- CDI request-scoped producer overhead
- Token claims extraction and response building
- HTTP payload processing
- Library integration overhead vs micro-benchmarks

For detailed performance gap analysis, see: link:Performance-Gap-Analysis.md[Performance Gap Analysis]

=== Performance Ceiling

* **Health check capacity**: 77.1K ops/s at 100 connections (peak performance)
* **JWT validation capacity**: 21.6K ops/s at 50-100 connections (cache enabled, 100% hit rate)
* **Performance gap**: 55.5K ops/s between health and JWT endpoints at peak
* **Stability range**: JWT maintains 20.1-21.6K ops/s across 50-300 connections (excellent stability)

**Throughput gap explanation:**

The 3.5x throughput difference (77K health vs 22K JWT) is primarily due to:
- **5x latency difference** (1.72ms JWT vs 0.345ms health)
- **1.86x more threads** (67 JWT vs 36 health) with worse per-thread efficiency
- **13% more CPU usage** (78% JWT vs 69% health)

The gap is **NOT caused by cryptographic validation** (only 0.21ms, 12% of latency), but by REST framework overhead (response building, serialization, HTTP processing).

== Conclusion

Comprehensive WRK stress testing across 50-300 connections reveals:

* **Peak performance**: 77.1K ops/s health (100 conns), 21.6K ops/s JWT (50-100 conns)
* **Excellent stability**: JWT maintains 20.1-21.6K ops/s across all connection counts (50-300)
* **Optimal configuration**: 100 connections provides best balance (77.1K health, 21.6K JWT)
* **Latency characteristics**: Health 0.573-3.77ms P50, JWT 2.05-12.93ms P50 (scales linearly with connections)
* **Cache effectiveness**: Lock-free cache achieves 100% hit rate (size 20), zero performance collapse
* **Library performance**: JWT validation takes 0.21ms (12% of latency) - library is fast, framework overhead dominates
* **Performance gap**: 55.5K ops/s difference due to framework overhead (68% unexplained latency), not cryptographic validation