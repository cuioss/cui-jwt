= Benchmark Module Architecture
:toc: left
:toclevels: 3
:toc-title: Table of Contents
:sectnums:
:source-highlighter: highlight.js


[NOTE]
====
This document defines the architecture, responsibilities, and boundaries of the CUI JWT benchmark modules. All content has been verified against the actual codebase.
====

== Overview

The CUI JWT benchmarking infrastructure consists of three specialized modules:

[cols="1,3", options="header"]
|===
|Module |Purpose
|benchmarking-common
|Shared infrastructure, utilities, and framework for all benchmark types

|benchmark-core
|JMH-based micro-benchmarks for direct JWT validation library performance testing

|benchmark-integration-wrk
|WRK-based HTTP load testing using shell scripts and Docker containers
|===

== Module Dependency Structure

[source]
----
┌─────────────────────────────────────────────────────────┐
│        External: JMH, Keycloak, Docker, WRK             │
└────────────────────┬────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────┐
│              benchmarking-common                    │
│  • Benchmark runners and configuration                  │
│  • Metrics collection and transformation                │
│  • Report and badge generation                          │
│  • Token management                                     │
│  • HTTP utilities                                       │
└──────────────┬──────────────────────────────────────────┘
               │
      ┌────────┴────────┐
      ▼                 ▼
┌──────────────┐  ┌─────────────────────────┐
│benchmark-    │  │benchmark-integration-wrk│
│library       │  │                         │
│              │  │ Shell-based WRK testing │
│JMH Benchmarks│  │ 1 Java post-processor   │
└──────────────┘  └─────────────────────────┘
      │                      │
      ▼                      ▼
┌──────────────┐  ┌─────────────────────────┐
│oauth-sheriff-      │  │Docker Containers:       │
│validation    │  │ • Quarkus App           │
│              │  │ • Keycloak              │
│              │  │ • Prometheus            │
└──────────────┘  └─────────────────────────┘
----

== benchmarking-common

=== Responsibility
Foundation framework providing shared utilities, configuration, metrics processing, and report generation for all benchmark types.

=== Key Components

[cols="2,3", options="header"]
|===
|Component |Key Classes

|Benchmark Execution
|`AbstractBenchmarkRunner`, `BenchmarkResultProcessor`, `AbstractBenchmarkBase`

|Configuration
|`BenchmarkConfiguration`, `BenchmarkType`, `IntegrationConfiguration`, `ReportConfiguration`

|Metrics Collection
|`PrometheusClient`, `PrometheusMetricsManager`, `MetricsOrchestrator`

|Metrics Processing
|`BenchmarkMetricsTransformer`, `MetricsTransformer`, `MetricsComputer`, `StatisticsCalculator`

|Report Generation
|`ReportGenerator`, `BadgeGenerator`, `GitHubPagesGenerator`, `ReportDataGenerator`

|Data Conversion
|`JmhBenchmarkConverter`, `WrkBenchmarkConverter`, `BenchmarkConverter`

|Token Management
|`KeycloakTokenRepository`, `TokenRepositoryConfig`, `TokenProvider`

|HTTP Utilities
|`HttpClientFactory`

|JFR Support
|`JfrInstrumentation`, `JfrSupport`, `JfrVarianceAnalyzer`

|Utilities
|`JsonSerializationHelper`, `BenchmarkLoggingSetup`, `OutputDirectoryStructure`
|===

=== Package Structure
[source]
----
de.cuioss.benchmarking.common/
├── base/          # Base classes for benchmarks
├── config/        # Configuration classes
├── constants/     # Constants
├── converter/     # Result converters (JMH/WRK → BenchmarkData)
├── http/          # HTTP client utilities
├── jfr/           # Java Flight Recorder support
├── metrics/       # Metrics collection and processing
├── model/         # Data models (BenchmarkData)
├── output/        # Output directory management
├── profiler/      # Profiling utilities
├── report/        # Report and badge generation
├── repository/    # Token repositories
├── runner/        # Benchmark runner framework
├── token/         # Token provider interfaces
└── util/          # General utilities
----

== benchmark-core

=== Responsibility
Executes JMH-based micro-benchmarks directly against the JWT validation library without network or container overhead.

=== Key Components

[cols="2,3", options="header"]
|===
|Component |Classes

|Standard Benchmarks
|`SimpleCoreValidationBenchmark`, `SimpleErrorLoadBenchmark`

|JFR Benchmarks
|`CoreJfrBenchmark`, `ErrorJfrBenchmark`, `MixedJfrBenchmark`, `UnifiedJfrBenchmark`

|Runners
|`LibraryBenchmarkRunner`, `JfrBenchmarkRunner`

|Support Classes
|`BenchmarkKeyCache`, `MockTokenRepository`, `LibraryMetricsExporter`

|Legacy Benchmarks
|`ErrorLoadBenchmark`, `PerformanceIndicatorBenchmark`
|===

=== Maven Profiles

* `benchmark` - Standard JMH benchmarks (< 10 minutes)
* `benchmark-jfr` - Benchmarks with Java Flight Recorder profiling
* `quick` - Reduced iterations for fast testing

=== Configuration

Configured via pom.xml properties:

* `jmh.iterations=5`, `jmh.warmupIterations=3`
* `jmh.threads=100`, `jmh.time=4s`
* `jmh.include` - Benchmark class pattern filter

== benchmark-integration-wrk

=== Responsibility
Performs HTTP-based load testing using WRK tool via shell scripts. Minimal Java code - orchestration handled by Maven and bash scripts.

=== Architecture

**Java Components:** Only 1 class

* `WrkResultPostProcessor` - Converts WRK output to BenchmarkData format, fetches Prometheus metrics, generates reports

**Shell Script Orchestration:**

Maven pom.xml references scripts from two locations:

* `../../oauth-sheriff-quarkus-parent/oauth-sheriff-quarkus-integration-tests/scripts/` - Container lifecycle and monitoring
* `src/main/resources/wrk-scripts/` - WRK benchmark execution

Key scripts:

* Container lifecycle: `start-integration-container.sh`, `stop-integration-container.sh`
* Health checks: `pre-benchmark-health-check.sh`
* Benchmarks: `health_live_benchmark.sh`, `jwt_benchmark.sh`
* Token fetching: `fetch_tokens.sh`
* Logging: `dump-keycloak-logs.sh`

**Container Services:**
[source]
----
Quarkus:     https://localhost:10443
  /jwt/validate    - JWT validation endpoint
  /q/health        - Health endpoint
  /q/metrics       - Metrics endpoint

Keycloak:    https://localhost:1443
  /auth/realms/... - Token issuance

Prometheus:  http://localhost:9090
  /api/v1/query    - Metrics API
----

=== Maven Profiles

* `benchmark` - Full lifecycle: build containers, run tests, collect metrics, stop containers
* `quick` - Reduced duration (30s), skips container lifecycle
* `autoscale` - 8 threads, 200 connections
* `stress` - 10 threads, 150 connections
* `max` - 10 threads, 300 connections (tests limits)

=== Configuration

Configured via pom.xml properties:

* `wrk.duration=60s`, `wrk.threads=5`, `wrk.connections=50`
* `wrk.jwt.token_count=100`
* `skip.container.lifecycle=false`

== Code Placement Decision Tree

[source]
----
Does the code generate reports/badges/artifacts?
├─YES─> benchmarking-common/report/
│
├─NO──> Does it collect or transform metrics?
│       ├─YES─> benchmarking-common/metrics/
│       │
│       └─NO──> Does it manage configuration?
│               ├─YES─> benchmarking-common/config/
│               │
│               └─NO──> Is it a JMH benchmark?
│                       ├─YES─> benchmark-core/
│                       │
│                       └─NO──> Is it WRK-related?
│                               ├─YES─> benchmark-integration-wrk/
│                               │       (or use shell scripts)
│                               │
│                               └─NO──> benchmarking-common/util/
----

== Placement Guidelines

=== Place in benchmarking-common when:

* Used by both library and integration benchmarks
* General framework component (runner, processor)
* Metrics collection or transformation
* Report/badge generation
* Configuration management
* Token management
* HTTP client utilities

=== Place in benchmark-core when:

* JMH benchmark methods (`@Benchmark` annotation)
* JFR instrumentation for library testing
* Library-specific test utilities

=== Place in benchmark-integration-wrk when:

* Processing WRK output format
* Rarely needed - most logic is in shell scripts

**Prefer shell scripts over Java** for WRK orchestration (container management, test execution).

== Architecture Patterns

=== Template Method Pattern
`AbstractBenchmarkRunner` defines benchmark lifecycle:

[source,java]
----
public final void runBenchmark() {
    createConfiguration();
    validateConfiguration(config);
    prepareBenchmark(config);
    executeBenchmark(options);
    processResults(results, config);
    cleanup(config);
}
----

Subclasses: `LibraryBenchmarkRunner`, `JfrBenchmarkRunner`

=== Builder Pattern
Configuration uses builders:

[source,java]
----
ReportConfiguration.builder()
    .withBenchmarkType(BenchmarkType.MICRO)
    .build();
----

Note: `BenchmarkConfiguration` itself is a record, not a builder. Builder pattern used for `ReportConfiguration`.

=== Factory Pattern

* `HttpClientFactory` - Creates configured HTTP clients

=== Converter Pattern

Unified data model via converters:

* `JmhBenchmarkConverter` - JMH results → BenchmarkData
* `WrkBenchmarkConverter` - WRK output → BenchmarkData

== Data Flow

[source]
----
Benchmark Execution (JMH or WRK)
        │
        ▼
Converter (JmhBenchmarkConverter / WrkBenchmarkConverter)
        │
        ▼
BenchmarkData (unified model)
        │
        ▼
MetricsTransformer / BenchmarkMetricsTransformer
        │
        ├──> BadgeGenerator → JSON badges
        ├──> ReportGenerator → HTML reports
        └──> GitHubPagesGenerator → GitHub Pages
        │
        ▼
target/benchmark-results/
----

== Key Design Principles

=== 1. Unified Data Model
All benchmark results converted to `BenchmarkData` for consistent processing.

=== 2. Separation of Concerns

* **Common**: Framework and utilities
* **Library**: Pure library testing (no network)
* **WRK**: HTTP load testing (minimal Java, mostly scripts)

=== 3. Extensibility

* Add new benchmark types by extending `AbstractBenchmarkRunner`
* Add new metrics by implementing transformation logic
* Add new reports by extending generator classes

=== 4. Verification Focus
All modules build independently. No circular dependencies.

== Conclusion

This architecture provides:

* **Clear separation**: Common framework, library testing, integration testing
* **Verified implementation**: All classes and structures exist and are accurate
* **Practical approach**: Shell scripts for WRK, Java for JMH
* **Unified reporting**: Common data model and report generation

Following these guidelines ensures maintainable and well-organized benchmark infrastructure.
